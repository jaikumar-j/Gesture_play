{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43e47ed-96d8-42ba-a891-ec0bd0a3fee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in ./.local/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: mediapipe in ./.local/lib/python3.10/site-packages (0.10.15)\n",
      "Requirement already satisfied: pyautogui in ./.local/lib/python3.10/site-packages (0.9.54)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./.local/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: absl-py in ./.local/lib/python3.10/site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in ./.local/lib/python3.10/site-packages (from mediapipe) (24.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in ./.local/lib/python3.10/site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in ./.local/lib/python3.10/site-packages (from mediapipe) (0.4.33)\n",
      "Requirement already satisfied: jaxlib in ./.local/lib/python3.10/site-packages (from mediapipe) (0.4.33)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: opencv-contrib-python in ./.local/lib/python3.10/site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in ./.local/lib/python3.10/site-packages (from mediapipe) (4.25.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in ./.local/lib/python3.10/site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: python3-Xlib in ./.local/lib/python3.10/site-packages (from pyautogui) (0.15)\n",
      "Requirement already satisfied: pymsgbox in ./.local/lib/python3.10/site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: pytweening>=1.0.4 in ./.local/lib/python3.10/site-packages (from pyautogui) (1.2.0)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in ./.local/lib/python3.10/site-packages (from pyautogui) (1.0.1)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in ./.local/lib/python3.10/site-packages (from pyautogui) (0.0.9)\n",
      "Requirement already satisfied: mouseinfo in ./.local/lib/python3.10/site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: pyrect in ./.local/lib/python3.10/site-packages (from pygetwindow>=0.0.5->pyautogui) (0.2.0)\n",
      "Requirement already satisfied: Pillow>=9.2.0 in ./.local/lib/python3.10/site-packages (from pyscreeze>=0.1.21->pyautogui) (10.4.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in ./.local/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in ./.local/lib/python3.10/site-packages (from jax->mediapipe) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum in ./.local/lib/python3.10/site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.10 in ./.local/lib/python3.10/site-packages (from jax->mediapipe) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pyperclip in ./.local/lib/python3.10/site-packages (from mouseinfo->pyautogui) (1.9.0)\n",
      "Requirement already satisfied: pycparser in ./.local/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python mediapipe pyautogui"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6549b78-1356-45b2-afb5-5f39625e88a8",
   "metadata": {},
   "source": [
    "Gesture Finger Base Even odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5413248d-8470-43d7-b478-648d7bc63c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 16:33:32.809569: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-23 16:33:33.102322: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-23 16:33:33.201528: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-23 16:33:33.229424: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-23 16:33:33.442510: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-23 16:33:34.496310: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745406215.145384    3648 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1745406215.147253    3724 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) UHD Graphics (TGL GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1745406215.185631    3715 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745406215.201257    3715 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745406217.723480    3714 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "/home/kiwitech/.local/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to count fingers and determine the number\n",
    "def count_fingers(landmarks):\n",
    "    # Define the landmark indices for the tips and base of each finger\n",
    "    tip_ids = [4, 8, 12, 16, 20]  # Thumb, Index, Middle, Ring, Pinky\n",
    "    base_ids = [2, 5, 9, 13, 17]  # Base of each finger\n",
    "\n",
    "    count_fingers = 0  # Initialize the finger count to 0\n",
    "\n",
    "    # Thumb detection (special case)\n",
    "    if landmarks[tip_ids[0]].x < landmarks[base_ids[0]].x:\n",
    "        count_fingers += 1  # Thumb is extended\n",
    "\n",
    "    # Check other fingers (Index, Middle, Ring, Pinky)\n",
    "    for i in range(1, 5):\n",
    "        if landmarks[tip_ids[i]].y < landmarks[base_ids[i]].y:\n",
    "            count_fingers += 1  # Finger is extended\n",
    "\n",
    "    return count_fingers\n",
    "\n",
    "# Function to check odd or even\n",
    "def odd_or_even(number):\n",
    "    return \"Even\" if number % 2 == 0 else \"Odd\"\n",
    "\n",
    "# Capture video from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process frame with MediaPipe Hands\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Draw hand landmarks\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Count fingers and determine the number\n",
    "            num_fingers = count_fingers(hand_landmarks.landmark)\n",
    "            result = odd_or_even(num_fingers)\n",
    "\n",
    "            # Display the result\n",
    "            cv2.putText(frame, f\"Number: {num_fingers} ({result})\", (10, 50),\n",
    "                         cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Hand Gesture Recognition\", frame)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a839dea-4fd0-4367-b998-eb67798720c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in ./.local/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: mediapipe in ./.local/lib/python3.10/site-packages (0.10.15)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./.local/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: absl-py in ./.local/lib/python3.10/site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in ./.local/lib/python3.10/site-packages (from mediapipe) (24.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in ./.local/lib/python3.10/site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in ./.local/lib/python3.10/site-packages (from mediapipe) (0.4.33)\n",
      "Requirement already satisfied: jaxlib in ./.local/lib/python3.10/site-packages (from mediapipe) (0.4.33)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: opencv-contrib-python in ./.local/lib/python3.10/site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in ./.local/lib/python3.10/site-packages (from mediapipe) (4.25.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in ./.local/lib/python3.10/site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in ./.local/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in ./.local/lib/python3.10/site-packages (from jax->mediapipe) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum in ./.local/lib/python3.10/site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.10 in ./.local/lib/python3.10/site-packages (from jax->mediapipe) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in ./.local/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python mediapipe"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbcba949-139e-4ea7-9c5b-ecbba08bb75d",
   "metadata": {},
   "source": [
    "Gesture Recognize Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b672dd-c5df-4f2e-ae0f-4474b334c8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746096613.129053    5542 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1746096613.131496    7695 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) UHD Graphics (TGL GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746096613.176773    7686 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746096613.194273    7684 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746096614.335390    7685 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Setup MediaPipe hand tracking\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Setup canvas for drawing\n",
    "canvas = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "# Drawing state\n",
    "drawing = False\n",
    "previous_position = None\n",
    "\n",
    "# Initialize webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame for a mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the frame to RGB for hand processing\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb)\n",
    "\n",
    "    # Check if hand landmarks are found\n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "        mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Get the tip of the index finger (landmark 8)\n",
    "        index_tip = hand_landmarks.landmark[8]\n",
    "        x = int(index_tip.x * 640)\n",
    "        y = int(index_tip.y * 480)\n",
    "\n",
    "        # Start drawing when the index finger moves\n",
    "        if previous_position:\n",
    "            # Draw a line from the previous position to the current one\n",
    "            cv2.line(canvas, previous_position, (x, y), (0, 255, 255), 5)\n",
    "\n",
    "        # Update the previous position\n",
    "        previous_position = (x, y)\n",
    "\n",
    "    # Show the frame and canvas\n",
    "    combined = cv2.add(frame, canvas)\n",
    "    cv2.imshow(\"Air Drawing - Gesture Control\", combined)\n",
    "\n",
    "    # Clear the canvas with 'c' key\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('c'):\n",
    "        canvas[:] = 0  # Clear canvas\n",
    "    elif key == ord('q'):\n",
    "        break  # Exit the loop\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f16301f4-3ee9-420e-958b-79beb99d290d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in ./.local/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: mediapipe in ./.local/lib/python3.10/site-packages (0.10.15)\n",
      "Requirement already satisfied: pyautogui in ./.local/lib/python3.10/site-packages (0.9.54)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./.local/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: absl-py in ./.local/lib/python3.10/site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in ./.local/lib/python3.10/site-packages (from mediapipe) (24.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in ./.local/lib/python3.10/site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in ./.local/lib/python3.10/site-packages (from mediapipe) (0.4.33)\n",
      "Requirement already satisfied: jaxlib in ./.local/lib/python3.10/site-packages (from mediapipe) (0.4.33)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: opencv-contrib-python in ./.local/lib/python3.10/site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in ./.local/lib/python3.10/site-packages (from mediapipe) (4.25.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in ./.local/lib/python3.10/site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: python3-Xlib in ./.local/lib/python3.10/site-packages (from pyautogui) (0.15)\n",
      "Requirement already satisfied: pymsgbox in ./.local/lib/python3.10/site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: pytweening>=1.0.4 in ./.local/lib/python3.10/site-packages (from pyautogui) (1.2.0)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in ./.local/lib/python3.10/site-packages (from pyautogui) (1.0.1)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in ./.local/lib/python3.10/site-packages (from pyautogui) (0.0.9)\n",
      "Requirement already satisfied: mouseinfo in ./.local/lib/python3.10/site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: pyrect in ./.local/lib/python3.10/site-packages (from pygetwindow>=0.0.5->pyautogui) (0.2.0)\n",
      "Requirement already satisfied: Pillow>=9.2.0 in ./.local/lib/python3.10/site-packages (from pyscreeze>=0.1.21->pyautogui) (10.4.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in ./.local/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in ./.local/lib/python3.10/site-packages (from jax->mediapipe) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum in ./.local/lib/python3.10/site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.10 in ./.local/lib/python3.10/site-packages (from jax->mediapipe) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.local/lib/python3.10/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pyperclip in ./.local/lib/python3.10/site-packages (from mouseinfo->pyautogui) (1.9.0)\n",
      "Requirement already satisfied: pycparser in ./.local/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python mediapipe pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08c63832-db08-4442-8599-235cad6a7072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback frame name: <module>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745303620.802582    7119 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1745303620.804481   10804 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) UHD Graphics (TGL GT2)\n",
      "W0000 00:00:1745303620.834747   10798 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745303620.857380   10799 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play/Pause\n",
      "Play/Pause\n",
      "Next\n",
      "Next\n",
      "Back\n",
      "Play/Pause\n",
      "Play/Pause\n",
      "Next\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pyautogui\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    1 / 0\n",
    "except Exception:\n",
    "    exc_type, exc_value, exc_tb = sys.exc_info()\n",
    "    print(\"Traceback frame name:\", exc_tb.tb_frame.f_code.co_name)\n",
    "\n",
    "# Initialize Mediapipe Hand\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(max_num_hands=1)\n",
    "\n",
    "# Setup webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "prev_gesture = None\n",
    "last_trigger_time = time.time()\n",
    "\n",
    "def detect_gesture(hand_landmarks):\n",
    "    fingers = []\n",
    "    tips_ids = [4, 8, 12, 16, 20]\n",
    "\n",
    "    # Thumb\n",
    "    if hand_landmarks.landmark[tips_ids[0]].x < hand_landmarks.landmark[tips_ids[0] - 1].x:\n",
    "        fingers.append(1)\n",
    "    else:\n",
    "        fingers.append(0)\n",
    "\n",
    "    # Other fingers\n",
    "    for id in range(1, 5):\n",
    "        if hand_landmarks.landmark[tips_ids[id]].y < hand_landmarks.landmark[tips_ids[id] - 2].y:\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "\n",
    "    return fingers\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip and convert color\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(rgb)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            fingers = detect_gesture(hand_landmarks)\n",
    "\n",
    "            current_time = time.time()\n",
    "            if current_time - last_trigger_time > 2:  # 2-second cooldown\n",
    "                if fingers == [0, 1, 0, 0, 0]:  # One finger (index) → forward\n",
    "                    pyautogui.press(\"right\")\n",
    "                    print(\"Next\")\n",
    "                    last_trigger_time = current_time\n",
    "                elif fingers == [0, 1, 1, 0, 0]:  # Two fingers → back\n",
    "                    pyautogui.press(\"left\")\n",
    "                    print(\"Back\")\n",
    "                    last_trigger_time = current_time\n",
    "                elif sum(fingers) == 5:  # All fingers → Play/Pause\n",
    "                    pyautogui.press(\"space\")\n",
    "                    print(\"Play/Pause\")\n",
    "                    last_trigger_time = current_time\n",
    "\n",
    "    cv2.imshow(\"Gesture Video Controller\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5f3bbc8-3589-419f-8440-e7bf2fc5c565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pygame in ./.local/lib/python3.10/site-packages (2.6.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pygame==2.6.0\n",
      "  Downloading pygame-2.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading pygame-2.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pygame\n",
      "  Attempting uninstall: pygame\n",
      "    Found existing installation: pygame 2.6.1\n",
      "    Uninstalling pygame-2.6.1:\n",
      "      Successfully uninstalled pygame-2.6.1\n",
      "Successfully installed pygame-2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame\n",
    "!pip install cv2 mediapipe numpy tensorflow pygame\n",
    "!python3 -m pip install -U pygame==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b36e0b4c-77b6-4539-8aa3-85834a79f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3ce51cb-5d06-4344-bd8f-4ea0dfec1333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745571600.798356    3448 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1745571600.799899    9871 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.3), renderer: Mesa Intel(R) UHD Graphics (TGL GT2)\n",
      "W0000 00:00:1745571600.829165    9866 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1745571600.863005    9868 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe's Hands model\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    " \n",
    "# Gesture labels\n",
    "gesture_labels = {\n",
    "    0: 'Left',\n",
    "    1: 'Right',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b66f6697-dd30-4164-be6e-cd6b0e07337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "window_width = 600\n",
    "window_height = 500\n",
    "window = pygame.display.set_mode((window_width, window_height))\n",
    "pygame.display.set_caption(\"Gesture-Based Game\")\n",
    " \n",
    "# Set up the player\n",
    "player_width = 40\n",
    "player_height = 40\n",
    "player_x = window_width // 2 - player_width // 2\n",
    "player_y = window_height - player_height - 10\n",
    "player_speed = 40\n",
    " \n",
    "# Set up multiple obstacles\n",
    "obstacle_width = 40\n",
    "obstacle_height = 40\n",
    "obstacle_speed = 20\n",
    "num_obstacles = 40\n",
    "obstacles = []\n",
    "\n",
    "for _ in range(num_obstacles):\n",
    "    obstacle_x = np.random.randint(0, window_width - obstacle_width)\n",
    "    obstacle_y = np.random.randint(-300, -50)  # Start off-screen at different positions\n",
    "    obstacles.append({'x': obstacle_x, 'y': obstacle_y})\n",
    "\n",
    "# Game over flag and text\n",
    "game_over = False\n",
    "game_over_text = pygame.font.Font('freesansbold.ttf', 64).render('Game Over', True, (255, 255, 255))\n",
    " \n",
    "# Restart button\n",
    "restart_button_text = pygame.font.Font('freesansbold.ttf', 32).render('Restart', True, (255, 255, 255))\n",
    "restart_button_rect = restart_button_text.get_rect()\n",
    "restart_button_rect.center = (window_width // 2, window_height // 2 + 50)\n",
    " \n",
    "# Game loop\n",
    "running = True\n",
    "clock = pygame.time.Clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "848c82fc-4aa1-43f1-9a88-7490a7268bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing video from webcam:\n",
    "cap = cv2.VideoCapture(0)\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "      \n",
    "    if event.type == pygame.MOUSEBUTTONDOWN and game_over:\n",
    "            mouse_pos = pygame.mouse.get_pos()\n",
    "            if restart_button_rect.collidepoint(mouse_pos):\n",
    "                # Restart the game\n",
    "                game_over = False\n",
    "                player_x = window_width // 2 - player_width // 2\n",
    "                obstacle_x = np.random.randint(0, window_width - obstacle_width)\n",
    "                obstacle_y = 0\n",
    " \n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    " \n",
    "    # Flip the frame horizontally for a mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    " \n",
    "# Detecting hand landmarks and recognizing gestures\n",
    "    results = hands.process(frame)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Get the index finger landmarks\n",
    "            index_finger_landmarks = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            index_finger_x = int(index_finger_landmarks.x * frame.shape[1])\n",
    "            index_finger_y = int(index_finger_landmarks.y * frame.shape[0])\n",
    " \n",
    "            # Recognize gesture based on index finger position\n",
    "            if index_finger_x < frame.shape[1] // 3:\n",
    "                gesture = 'Left'\n",
    "                player_x -= player_speed\n",
    "            elif index_finger_x > frame.shape[1] * 2 // 3:\n",
    "                gesture = 'Right'\n",
    "                player_x += player_speed\n",
    "            else:\n",
    "                gesture = 'Neutral'\n",
    " \n",
    "            # Draw a circle at the index finger position\n",
    "            cv2.circle(frame, (index_finger_x, index_finger_y), 10, (0, 255, 0), -1)\n",
    " \n",
    "            # Draw the recognized gesture on the frame\n",
    "            cv2.putText(frame, gesture, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    " \n",
    "    cv2.imshow('Gesture Recognition', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Updating the player's position\n",
    "    if not game_over:\n",
    "        # Update the player's position\n",
    "        if player_x < 0:\n",
    "            player_x = 0\n",
    "        elif player_x > window_width - player_width:\n",
    "            player_x = window_width - player_width\n",
    " \n",
    "        # Update the obstacle's position\n",
    "        obstacle_y += obstacle_speed\n",
    " \n",
    "        # Check for collision between the player and the obstacle\n",
    "        if player_x < obstacle_x + obstacle_width and \\\n",
    "                player_x + player_width > obstacle_x and \\\n",
    "                player_y < obstacle_y + obstacle_height and \\\n",
    "                player_y + player_height > obstacle_y:\n",
    "            # Game over\n",
    "            game_over = True\n",
    " \n",
    "        # Reset the obstacle if it goes off the screen\n",
    "        if obstacle_y > window_height:\n",
    "            obstacle_x = np.random.randint(0, window_width - obstacle_width)\n",
    "            obstacle_y = 0\n",
    " \n",
    "        # Clear the window\n",
    "        window.fill((0, 0, 0))\n",
    " \n",
    "# Creating player and obstacle:\n",
    "        pygame.draw.rect(window, (255, 255, 255), (player_x, player_y, player_width, player_height))\n",
    " \n",
    "        # Draw the obstacle\n",
    "        pygame.draw.rect(window, (255, 0, 0), (obstacle_x, obstacle_y, obstacle_width, obstacle_height))\n",
    " \n",
    "    # Display \"Game Over\" text if game over\n",
    "    if game_over:\n",
    "        window.blit(game_over_text, \n",
    "                    (window_width // 2 - game_over_text.get_width() // 2,\n",
    "                     window_height // 2 - game_over_text.get_height() // 2))\n",
    "        pygame.draw.rect(window, (0, 0, 255), restart_button_rect)\n",
    "        window.blit(restart_button_text, restart_button_rect)\n",
    " \n",
    "    # Update the display\n",
    "    pygame.display.update()\n",
    " \n",
    "    # Limit the frame rate\n",
    "    clock.tick(60)\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c9e606-f48f-4f18-ac52-bd6651351745",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data.pickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "data_dict = pickle.load(open('./data.pickle', 'rb'))\n",
    "data = np.asarray(data_dict['data'])\n",
    "labels = np.asarray(data_dict['labels'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle=True, stratify=labels)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "score = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print('{}% of samples were classified correctly !'.format(score * 100))\n",
    "\n",
    "f = open('model.p', 'wb')\n",
    "pickle.dump({'model': model}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a474f-0593-4ad5-bf5d-79150c188582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
